{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seet for numpy\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC = 0.5  # use 10 percent of authors for training\n",
    "TEST_FRAC = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../out/reddit_chunked/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path + \"reddit_train_embeddings_20240126_181755.pickle\", \"rb\") as f:\n",
    "    train_chunks = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "with open(folder_path + \"reddit_test_embeddings_20240126_181755.pickle\", \"rb\") as f:\n",
    "    test_chunks = pickle.load(f)\n",
    "\n",
    "\n",
    "all_chunks = train_chunks + test_chunks\n",
    "all_chunks = all_chunks[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2embedding = {\n",
    "    elem[\"text\"]: elem[\"embedding\"] for elem in all_chunks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame(all_chunks)[[\"metadata\", \"text\"]]\n",
    "df_total[\"author\"] = df_total[\"metadata\"].apply(lambda x: x['author'])\n",
    "df = df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nunique_authors = df[\"author\"].unique()\\nnp.random.shuffle(unique_authors)\\n\\ntrain_authors = unique_authors[:int(len(unique_authors) * TRAIN_FRAC)]\\ntest_authors = unique_authors[int(len(unique_authors) * TRAIN_FRAC):]\\n\\ntrain_df = df[df[\"author\"].isin(train_authors)].sort_values(by=\"author\")\\ntest_df = df[df[\"author\"].isin(test_authors)].sort_values(by=\"author\")\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unique_authors = df[\"author\"].unique()\n",
    "np.random.shuffle(unique_authors)\n",
    "\n",
    "train_authors = unique_authors[:int(len(unique_authors) * TRAIN_FRAC)]\n",
    "test_authors = unique_authors[int(len(unique_authors) * TRAIN_FRAC):]\n",
    "\n",
    "train_df = df[df[\"author\"].isin(train_authors)].sort_values(by=\"author\")\n",
    "test_df = df[df[\"author\"].isin(test_authors)].sort_values(by=\"author\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df = df.sample(frac=1, replace=False, random_state=42)\n",
    "train_df = df.iloc[:int(len(df_total) * TRAIN_FRAC)]\n",
    "test_df = df.iloc[int(len(df_total) * TRAIN_FRAC):]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "SelfishThailand        602\n",
       "Jmtaylor1991           207\n",
       "RHGOtakuxxx            164\n",
       "AtLeastIAmNotOnFire    147\n",
       "fadedblackleggings     127\n",
       "                      ... \n",
       "COB98                    5\n",
       "janbogi2011              5\n",
       "wwstewart                4\n",
       "thewayofxen              4\n",
       "quietcranberry           3\n",
       "Name: count, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"author\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "SelfishThailand        600\n",
       "Jmtaylor1991           231\n",
       "RHGOtakuxxx            173\n",
       "AtLeastIAmNotOnFire    161\n",
       "fadedblackleggings     135\n",
       "                      ... \n",
       "scoofy                   6\n",
       "firemonkey57             5\n",
       "1cecream4breakfast       5\n",
       "Ruludos                  3\n",
       "aft33                    3\n",
       "Name: count, Length: 233, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"author\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_df: 5000\n",
      "Length of test_df: 5000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train_df: {len(train_df)}\")\n",
    "print(f\"Length of test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_up_same_author(df):\n",
    "    # permute entire dataframe \n",
    "    old_df = deepcopy(df).sort_values(by=\"author\")\n",
    "    new_df = deepcopy(df).sample(frac=1, replace=False)\n",
    "\n",
    "    # sort dataframe again by author to keep random order within author\n",
    "    new_df = new_df.sort_values(by=[\"author\"], kind = \"stable\")\n",
    "\n",
    "    # rename all columns in parnter dataframe to avoid confusion\n",
    "    new_df.columns = [str(col) + \"_partner\" for col in new_df.columns]\n",
    "    \n",
    "    colnames = list(old_df.columns) + list(new_df.columns)\n",
    "\n",
    "    # horizontally concatenate the two dataframes ignoring the index\n",
    "    new_df = pd.concat([old_df.reset_index(drop = True), new_df.reset_index(drop = True)], axis=1, ignore_index=True)\n",
    "    new_df.columns = colnames\n",
    "\n",
    "    assert new_df[\"author\"].equals(new_df[\"author_partner\"]) # check if all authors are the same\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "def pair_up_different_author(df, iterations=10):\n",
    "    df_idx = df[[\"author\"]]\n",
    "    df_idx[\"old_idx\"] = range(len(df_idx))\n",
    "\n",
    "    pair_idx_df_list = []\n",
    "    for _ in range(iterations):\n",
    "        shuffled_df = df_idx.sample(frac=1, replace = False).reset_index(drop=True)\n",
    "\n",
    "        shuffled_df.rename(columns={\"author\": \"author_partner\", \"old_idx\": \"old_idx_partner\"}, inplace=True)\n",
    "\n",
    "        paired_df = pd.concat([deepcopy(df_idx).reset_index(drop=True), deepcopy(shuffled_df).reset_index(drop=True),], axis=1)\n",
    "\n",
    "        pair_idx_df_list.append(paired_df)\n",
    "\n",
    "    pair_idx_df = pd.concat(pair_idx_df_list, axis=0, ignore_index=True)\n",
    "    \n",
    "    # remove rows where author is the same\n",
    "    pair_idx_df = pair_idx_df[pair_idx_df[\"author\"] != pair_idx_df[\"author_partner\"]]\n",
    "\n",
    "    # drop duplicates for old indices \n",
    "    pair_idx_df = pair_idx_df.drop_duplicates(subset=[\"old_idx\"])   \n",
    "    \n",
    "    assert len(pair_idx_df) == len(df)\n",
    " \n",
    "    # order rows of origal df according to old_idx\n",
    "    pair_df = df.iloc[pair_idx_df[\"old_idx_partner\"].values, :]\n",
    "    pair_df.columns = [str(col) + \"_partner\" for col in pair_df.columns]\n",
    "\n",
    "    # concat df and pair_df\n",
    "    pair_df = pd.concat([df.reset_index(drop=True), pair_df.reset_index(drop=True)], axis=1, ignore_index=False)\n",
    "\n",
    "\n",
    "    assert pair_df[\"author\"].equals(pair_df[\"author_partner\"]) == False # check if all authors are the same\n",
    "\n",
    "    return pair_df\n",
    "\n",
    "def pair_up_different_author_baseline(df):\n",
    "    # just pair up the dataframe with a random permutation of itself\n",
    "\n",
    "    # permute entire dataframe\n",
    "    new_df = deepcopy(df).sample(frac=1, replace=False)\n",
    "\n",
    "    # rename all columns in parnter dataframe to avoid confusion\n",
    "    new_df.columns = [str(col) + \"_partner\" for col in new_df.columns]\n",
    "\n",
    "    colnames = list(df.columns) + list(new_df.columns)\n",
    "\n",
    "    # horizontally concatenate the two dataframes ignoring the index\n",
    "    new_df = pd.concat([df.reset_index(drop = True), new_df.reset_index(drop = True)], axis=1, ignore_index=True)\n",
    "    new_df.columns = colnames\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your dataframe 'df'\n",
    "# result_df = pair_up_different_author(df)\n",
    "\n",
    "\n",
    "def create_pair_classification_df(df, clean_columns=True):\n",
    "    # create dataframe with same author pairs\n",
    "    same_author_df = pair_up_same_author(df)\n",
    "    # create dataframe with different author pairs\n",
    "    different_author_df = pair_up_different_author_baseline(df)\n",
    "\n",
    "    colnames_same_author_df = list(same_author_df.columns)\n",
    "    colnames_different_partner_df = list(different_author_df.columns)\n",
    "\n",
    "    # make sure that the columns are all of type string \n",
    "    colnames_same_author_df = [str(col) for col in colnames_same_author_df]\n",
    "    colnames_different_partner_df = [str(col) for col in colnames_different_partner_df]\n",
    "\n",
    "    assert len(colnames_same_author_df) == len(colnames_different_partner_df)\n",
    "    assert all([colnames_different_partner_df[i] == colnames_different_partner_df[i] for i in range(len(colnames_same_author_df))])\n",
    "\n",
    "    # rename columns in partner dataframe to avoid confusion\n",
    "    \n",
    "    same_author_df.columns = colnames_same_author_df\n",
    "    different_author_df.columns = colnames_different_partner_df\n",
    "    \n",
    "    #same_author_df[\"label\"] = 1\n",
    "    #different_author_df[\"label\"] = 0\n",
    "\n",
    "    pair_classification_df = pd.concat([same_author_df, different_author_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    pair_classification_df = pair_classification_df.sample(frac=1, replace=False)\n",
    "\n",
    "    pair_classification_df[\"label\"] = pair_classification_df[\"author\"] == pair_classification_df[\"author_partner\"]\n",
    "\n",
    "    if clean_columns:\n",
    "        pair_classification_df.drop(columns = [\n",
    "            \"author\",\n",
    "            \"author_partner\",\n",
    "            \"metadata\",\n",
    "            \"metadata_partner\",\n",
    "            \"text\",\n",
    "            \"text_partner\"\n",
    "        ], inplace=True)\n",
    "\n",
    "    \n",
    "    return pair_classification_df\n",
    "\n",
    "\n",
    "def create_pair_classification_df_upsample(df, clean_columns, sample_ratio = 1):\n",
    "    ### use the craete_pair_classification_df function to create a pair classification dataframe. But stack several of them on top of each other to upsample the different author pairs\n",
    "\n",
    "    classification_df_lis = []\n",
    "    for _ in tqdm(range(sample_ratio)):\n",
    "        classification_df_lis.append(create_pair_classification_df(deepcopy(df), clean_columns=clean_columns))\n",
    "\n",
    "    classification_df = pd.concat(classification_df_lis, axis=0, ignore_index=False)\n",
    "    classification_df = classification_df.sample(frac=1, replace=False)\n",
    "\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_df(df, text2embedding):\n",
    "    embedding_list = [\n",
    "        text2embedding[text] for text in df[\"text\"]\n",
    "    ]\n",
    "    embedding_df = pd.DataFrame(embedding_list)\n",
    "\n",
    "    embedding_list_partner = [\n",
    "        text2embedding[text] for text in df[\"text_partner\"]\n",
    "    ]\n",
    "    embedding_df_partner = pd.DataFrame(embedding_list_partner)\n",
    "    embedding_df_partner.columns = [str(col) + \"_partner\" for col in embedding_df_partner.columns]\n",
    "\n",
    "    df = pd.concat([df.reset_index(drop=True), embedding_df.reset_index(drop=True), embedding_df_partner.reset_index(drop=True)], axis=1, ignore_index=False)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 47.18it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 92.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df_paired = create_pair_classification_df_upsample(train_df, clean_columns = False, sample_ratio = 2)\n",
    "test_df_paired = create_pair_classification_df_upsample(test_df, clean_columns = False, sample_ratio = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = add_embeddings_to_df(train_df_paired, text2embedding)\n",
    "test_df = add_embeddings_to_df(test_df_paired, text2embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.iloc[:, 6:]\n",
    "test_df = test_df.iloc[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a predictor with a neural network \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240127_153458\"\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240127_153458\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.15 GB / 15.71 GB (13.7%)\n",
      "Disk Space Avail:   3.23 GB / 474.72 GB (0.7%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    20000\n",
      "Train Data Columns: 3072\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [False, True]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2225.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 468.75 MB (21.1% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 21.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 3072 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 3072 | ['0', '1', '2', '3', '4', ...]\n",
      "\t51.9s = Fit runtime\n",
      "\t3072 features in original data used to generate 3072 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 468.75 MB (9.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 53.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18000, Val Rows: 2000\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "}\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1746.89s of the 1746.82s of remaining time.\n",
      "\t0.602\t = Validation score   (accuracy)\n",
      "\t56.42s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1689.97s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.602\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 118.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240127_153458\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x1ea1c9e8610>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='label')\n",
    "predictor.fit(train_df, time_limit=60*30, \n",
    "            presets='medium_quality',\n",
    "            hyperparameters={'NN_TORCH': {}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.64255\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.64255,\n",
      "    \"balanced_accuracy\": 0.6451344398138645,\n",
      "    \"mcc\": 0.2970781214324763,\n",
      "    \"roc_auc\": 0.7112786677473117,\n",
      "    \"f1\": 0.6048748134637705,\n",
      "    \"precision\": 0.6962717903041099,\n",
      "    \"recall\": 0.5346882939222201\n",
      "}\n",
      "Detailed (per-class) classification report:\n",
      "{\n",
      "    \"False\": {\n",
      "        \"precision\": 0.6077753068116301,\n",
      "        \"recall\": 0.7555805857055089,\n",
      "        \"f1-score\": 0.6736659515223445,\n",
      "        \"support\": 9766.0\n",
      "    },\n",
      "    \"True\": {\n",
      "        \"precision\": 0.6962717903041099,\n",
      "        \"recall\": 0.5346882939222201,\n",
      "        \"f1-score\": 0.6048748134637705,\n",
      "        \"support\": 10234.0\n",
      "    },\n",
      "    \"accuracy\": 0.64255,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.65202354855787,\n",
      "        \"recall\": 0.6451344398138645,\n",
      "        \"f1-score\": 0.6392703824930575,\n",
      "        \"support\": 20000.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.653058957414732,\n",
      "        \"recall\": 0.64255,\n",
      "        \"f1-score\": 0.6384655261777722,\n",
      "        \"support\": 20000.0\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.64255, 'balanced_accuracy': 0.6451344398138645, 'mcc': 0.2970781214324763, 'roc_auc': 0.7112786677473117, 'f1': 0.6048748134637705, 'precision': 0.6962717903041099, 'recall': 0.5346882939222201, 'confusion_matrix':        False  True \n",
      "False   7379   2387\n",
      "True    4762   5472, 'classification_report': {'False': {'precision': 0.6077753068116301, 'recall': 0.7555805857055089, 'f1-score': 0.6736659515223445, 'support': 9766.0}, 'True': {'precision': 0.6962717903041099, 'recall': 0.5346882939222201, 'f1-score': 0.6048748134637705, 'support': 10234.0}, 'accuracy': 0.64255, 'macro avg': {'precision': 0.65202354855787, 'recall': 0.6451344398138645, 'f1-score': 0.6392703824930575, 'support': 20000.0}, 'weighted avg': {'precision': 0.653058957414732, 'recall': 0.64255, 'f1-score': 0.6384655261777722, 'support': 20000.0}}}\n"
     ]
    }
   ],
   "source": [
    "print(predictor.evaluate(test_df, silent=False, detailed_report =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = predictor.leaderboard(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.72460</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.886754</td>\n",
       "      <td>0.287154</td>\n",
       "      <td>62.391248</td>\n",
       "      <td>1.886754</td>\n",
       "      <td>0.287154</td>\n",
       "      <td>62.391248</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.72460</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.890753</td>\n",
       "      <td>0.291260</td>\n",
       "      <td>62.820122</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.428874</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.62805</td>\n",
       "      <td>0.5055</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.958664</td>\n",
       "      <td>0.153063</td>\n",
       "      <td>238.239205</td>\n",
       "      <td>0.958664</td>\n",
       "      <td>0.153063</td>\n",
       "      <td>238.239205</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.61535</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.223486</td>\n",
       "      <td>0.163531</td>\n",
       "      <td>185.544983</td>\n",
       "      <td>1.223486</td>\n",
       "      <td>0.163531</td>\n",
       "      <td>185.544983</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.59530</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.090229</td>\n",
       "      <td>0.148110</td>\n",
       "      <td>24.281408</td>\n",
       "      <td>1.090229</td>\n",
       "      <td>0.148110</td>\n",
       "      <td>24.281408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.58950</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.136361</td>\n",
       "      <td>0.143613</td>\n",
       "      <td>24.101726</td>\n",
       "      <td>1.136361</td>\n",
       "      <td>0.143613</td>\n",
       "      <td>24.101726</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0       NeuralNetTorch     0.72460     0.7035    accuracy        1.886754   \n",
       "1  WeightedEnsemble_L2     0.72460     0.7035    accuracy        1.890753   \n",
       "2     RandomForestEntr     0.62805     0.5055    accuracy        0.958664   \n",
       "3     RandomForestGini     0.61535     0.5130    accuracy        1.223486   \n",
       "4       ExtraTreesEntr     0.59530     0.4940    accuracy        1.090229   \n",
       "5       ExtraTreesGini     0.58950     0.4810    accuracy        1.136361   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.287154   62.391248                 1.886754                0.287154   \n",
       "1       0.291260   62.820122                 0.003999                0.004106   \n",
       "2       0.153063  238.239205                 0.958664                0.153063   \n",
       "3       0.163531  185.544983                 1.223486                0.163531   \n",
       "4       0.148110   24.281408                 1.090229                0.148110   \n",
       "5       0.143613   24.101726                 1.136361                0.143613   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          62.391248            1       True          5  \n",
       "1           0.428874            2       True          6  \n",
       "2         238.239205            1       True          2  \n",
       "3         185.544983            1       True          1  \n",
       "4          24.281408            1       True          4  \n",
       "5          24.101726            1       True          3  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
